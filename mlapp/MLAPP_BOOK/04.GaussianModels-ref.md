# 04 高斯模型


[原文] https://probml.github.io/pml-book/book0.html

[作者] [Kevin Patrick Murphy](https://www.cs.ubc.ca/~murphyk/)

<style>p{text-indent:2em;2}</style>



## 4.1 引言

本章我们将介绍多变量高斯（multivariate Gaussian）或者多变量正态（multivariate normal，MVN）分布，在连续随机变量领域中，它经常被用来建立联合概率密度函数。该分布是我们在后文中介绍的很多模型的基础。

不幸的是，本章所需要的数学知识水平要比很多其他章节的高。特别是在线性代数和矩阵计算方面，本章将严重依赖这些知识。为了处理高维数据，这些知识都是必须的。初学者可以选择跳过那些加星号的章节。除此之外，因为本章有很多公式，我们会将那些特别重要的公式用方框进行标注。

### 4.1.1 符号表达

首先让我们简单介绍一些符号书写方面的规范。我们使用小写的加粗字母表示向量，比如 x。使用大写的加粗字母表示矩阵，比如 X。我们使用大写非加粗字母表示矩阵中的元素，比如 $X_{ij}$ 。

所有的向量在没有特殊说明的情况下都是列向量。我们使用 $[x_1,...,x_D]$ 表示由 $\mathcal{D}$ 个标量组成的列向量。类似地，符号  $x=[x_1,...,x_D]$  的等号左边表示一个特别高的列向量，由每个向量 $x_i$ 延纵向叠加而成。这种方式还有一种替代写法 $x=(x_1^T,...,x_D^T)^T$ ，但这种写法比较丑陋。符号 $X=[x_1,...,x_D]$ 的等式左边代表一个矩阵，由每个向量 $x_i$ 延横向叠加而成。

### 4.1.2 基础知识

根据章节 2.5.2 的内容，我们知道在 $\mathcal{D}$ 维空间中 MVN 的概率密度函数定义为：

$$
N(x|\mu,\Sigma)\overset{*}{=} \frac{1}{(2\pi)^{D/2}|\Sigma |^{1/2}}\exp[ -\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu)] \tag{4.1}
$$

上式中指数项中表达式为向量 $\mathbf{x}$ 和均值向量 $\mu$ 之间的马氏距离。通过将矩阵进行特征分解（eigendecomposition），我们可以对马氏距离有更深的理解。  $\Sigma$ 的分解式可以写成 $\Sigma = U\Lambda U ^T$ ，其中 $U$ 为特征向量的标准正交矩阵，满足 $U^T U = I$ ， $\Lambda$ 为对应特征值的构成的对角矩阵。

使用特征分解，我们有：

$$
\Sigma^{-1}=U^{-T}\Lambda^{-1}U^{-1}=U\Lambda ^{-1}U^T=\sum^D_{i=1}\frac{1}{\lambda_i}u_iu_i^T \tag{4.2}
$$

其中 $u_i$ 表示矩阵 $U$ 的第 $i$ 列，表示第 $i$ 个特征向量。所以我们可以重写马氏距离为：

\begin{align*}
(x-\mu)^T\Sigma^{-1}(x-\mu)&=(x-\mu)^T(\sum^D_{i=1}\frac{1}{\lambda_i}u_iu_i^T)(x-\mu) \tag{4.3}\\
&= \sum^D_{i=1}\frac{1}{\lambda_i}(x-\mu)^Tu_iu_i^T(x-\mu)=\sum^D_{i=1}\frac{y_i^2}{\lambda_i} \tag{4.4}
\end{align*}

其中 $y_i\overset{*}{=} u_i^T(x-\mu)$。回忆一下在 2 维空间中椭圆的曲线：

$$
\frac{y_1^2}{\lambda_1}+\frac{y_2^2}{\lambda_2}=1 \tag{4.5}
$$

![](media/image22.png){width="3.5308081802274716in" height="2.92671697287839in"}

图 4.1 二维高斯密度的可视化。椭圆的长短轴分别由协方差矩阵的前两个特征向量（对应的特征值分别为最大和次最大）决定，分别为 $u_1$ 和 $u_2$ 。

所以，我们发现对于一个多维高斯分布而言，其概率密度等高线的轮廓线是一个椭圆，如图 4.1 所示。特征向量决定了这个椭圆的方向，特征值决定了对应方向曲线延长的程度。

一般情况下，我们将马氏距离等价为一个新的坐标系中的欧式距离，这个新的坐标系可以通过将现有坐标系（即图 4.1 中的 $x$ - $y$ 坐标系）按方向平移  $\mu$ ，按 $U$ 旋转得到。

### 4.1.3 MVN 的极大似然解 MLE

接下来，我们讨论如何使用 MLE 对 MVN 中的参数进行估计。在后面的章节中，我们将会讨论使用贝叶斯方法对参数进行推断，这种方法可以缓解过拟合，并且可以用来量化参数估计值的不确定度。

定理 4.1.1（高斯分布的 MLE）。
如果有 $N$ 个独立同分布样本符合正态分布，即 $x_i \sim  N(\mu,\Sigma)$，则对参数的最大似然估计为：
$$
\hat\mu_{mle}=\frac{1}{N}\sum^N_{i=1}x_i \overset{*}{=} \bar x \tag{4.6}
$$

$$
\hat\Sigma_{mle}=\frac{1}{N}\sum^N_{i=1}(x_i-\bar x)(x_i-\bar x)^T=\frac{1}{N}(\sum^N_{i=1}x_ix_i^T)-\bar x\bar x^T \tag{4.7}
$$

不难发现，MLE 只是单纯的经验期望和经验方差。在单变量高斯分布中，我们有相似的结果：

$$
\hat\mu =\frac{1}{N}\sum_ix_i=\bar x \tag{4.8}
$$

$$
\hat\sigma^2 =\frac{1}{N}\sum_i(x_i-x)^2=(\frac{1}{N}\sum_ix_i^2)-\bar x^2 \tag{4.9}
$$

#### 4.1.3.1 证明

为了证明 4.1.3 的结论，我们需要一些线性代数中的结论，我们将在下面列出。在下式中，a 和 b 为向量，A 和 B 为矩阵。符号 tr(A) 表示矩阵的迹（trace），定义为矩阵对角线元素的和： $tr(A)=\sum_i A_{ii}$ 。

\begin{align*}
\frac{\partial(b^Ta)}{\partial a}&=b \tag{4.10}\\
\frac{\partial(a^TAa)}{\partial a}&=(A+A^T)a\\
\frac{\partial}{\partial A} tr(BA)&=B^T\\
\frac{\partial}{\partial A} \log|A|&=A^{-T}\overset{*}{=} (A^{-1})^T\\
tr(ABC)=tr(CAB)&=tr(BCA)
\end{align*}

最后一个等式被称为迹运算的循环置换性质（cyclic permutation property）。使用这个性质，我们可以推导出广泛使用的迹技巧（trace trick），这种技巧将标量内积 $x^TAx$ 进行重新排序。

$$
x^TAx=tr(x^TAx)=tr(xx^TA)=tr(Axx^T) \tag{4.11}
$$

基于上述基本定理，接下来我们就可以展开证明。已知对数似然函数为：

$l(\mu,\Sigma)=\log p(D|\mu,\Sigma)=\frac{N}{2}\log|\Lambda| -\frac{1}{2}\sum^N_{i=1}(x_i-\mu)^T\Lambda (x_i-\mu)$(4.12)

上式中$\Lambda=\Sigma^{-1}$,是精度矩阵(precision matrix)

然后进行一个替换(substitution)$y_i=x_i-\mu$,再利用微积分的链式法则:

$$
\begin{aligned}
\frac{\partial}{\partial\mu} (x_i-\mu)^T\Sigma^{-1}(x_i-\mu) &=  \frac{\partial}{\partial y_i}y_i^T\Sigma^{-1}y_i\frac{\partial y_i}{\partial\mu}   &\text{(4.13)}\\
&=-1(\Sigma_{-1}+\Sigma^{-T})y_i &\text{(4.14)}\\
\end{aligned}
$$

因此:

$$
\begin{aligned}
\frac{\partial}{\partial\mu}l(\mu.\Sigma) &= -\frac{1}{2} \sum^N_{i=1}-2\Sigma^{-1}(x_i-\mu)=\Sigma^{-1}\sum^N_{i=1}(x_i-\mu)=0 &\text{(4.15)}\\
&=-1(\Sigma_{-1}+\Sigma^{-T})y_i &\text{(4.16)}\\
\end{aligned}
$$
所以$\mu$的最大似然估计(MLE)就是经验均值(empirical mean).

然后利用求迹运算技巧(trace-trick)来重写对$\Lambda$的对数似然函数:
$$
\begin{aligned}
l(\Lambda)&=  \frac{N}{2}\log|\Lambda|-\frac{1}{2}\sum_i tr[(x_i-\mu)(x_i-\mu)^T\Lambda] &\text{(4.17)}\\
&= \frac{N}{2}\log|\Lambda| -\frac{1}{2}tr[S_{\mu}\Lambda]&\text{(4.18)}\\
& &\text{(4.19)}\\
\end{aligned}
$$

上式中
$S_{\mu}\overset{*}{=} \sum^N_{i=1}(x_i-\mu)(x_i-\mu)^T$(4.20)

是以$\mu$为中心的一个散布矩阵(scatter matrix).对上面的表达式关于$\Lambda$进行求导就得到了:
$$
\begin{aligned}
\frac{\partial l(\Lambda)}{\partial\Lambda} & = \frac{N}{2}\Lambda^{-T} -\frac{1}{2}S_{\mu}^T=0 &\text{(4.21)}\\
\Lambda^{-T} & = \Lambda^{-1}=\Sigma=\frac{1}{N}S_{\mu} &\text{(4.22)}\\
\end{aligned}
$$

因此有:
$\hat\Sigma=\frac{1}{N}\sum^N_{i=1}(x_i-\mu)(x_i-\mu)^T$(4.23)

正好也就是以$\mu$为中心的经验协方差矩阵(empirical covariance matrix).如果插入最大似然估计$\mu=\bar x$(因为所有参数都同时进行优化),就得到了协方差矩阵的最大似然估计的标准方程。

### 4.1.4 高斯分布的最大熵性质推导

本节，我们将展示在给定期望和协方差矩阵的前提下，多维高斯分布是所有分布中信息熵最大的分布（9.2.6 节同样介绍）。这是高斯分布被广泛使用的理由之一：一个分布的一阶矩（均值） $\mu$ 和二阶矩（方差） $\sigma$ 通常是能从现有数据中可靠估计出来的全部统计量，所以我们希望概率分布能够充分服从这两个统计量，而尽量不再去做其他额外的假设。

为了简化符号的书写，我们假设期望为 0，相应的概率密度函数的形式为：

$p(x)=\frac{1}{Z}\exp (-\frac{1}{2}x^T\Sigma^{-1}x)$（4.23）

如果我们定义 $f_{ij} (x) = x_i x_j , \lambda_{ij} = \frac{1}{2} (\Sigma^{-1})_{ij}\\ i, j \in \{1, ... , D\}$ 和！[](media/image53.wmf)，其中！[](media/image54.wmf)，此时上式的形式与式 9.74 一致。上述分布的（微分）熵（使用* e *作为对数的底）为：

$h(N(\mu,\Sigma))  =\frac{1}{2}\ln[(2\pi e)^D|\Sigma|]$ （4.24）

我们现在展示，MVN 是在给定协方差矩阵 $\Sigma$ 的前提下熵最大的分布。

#### 定理 4.1.2.

令* q*(x) 为满足！[](media/image56.wmf) 的任意概率密度函数。令！[](media/image57.wmf)。我们有！[](media/image58.wmf).

证明：我们有：

![](media/image59.wmf) （4.25）

![](media/image60.wmf) （4.26）

![](media/image61.wmf) （4.27）

![](media/image62.wmf) （4.28）

关键步骤 4.27 式（标、*号）成立的原因是因为我们要求* p *和* q *的协方差矩阵一样。附：关于式 4.27 的证明（注意：我们在下面采用 ln 表示以* e *为底的对数，读者在下面的证明过程中，也可以思考为什么高斯分布的微分熵与期望！[](media/image63.wmf) 无关，即式 4.24 右边中为什么没有期望项）：

![](media/image64.wmf)

![](media/image65.wmf)

于是我们有：

![](media/image66.wmf)

![](media/image67.wmf)

4.2 高斯判别分析

MVN 的一个重要应用在于：在生成式分类器中定义类条件概率密度，比如：

![](media/image68.wmf) （4.29）

运用上式的直接结果是引出一个技术叫（高斯）判别分析（discriminant analysis）或者叫 GDA（尽管这是生成式而非判别式分类器------章节 8.6 将会进行更多讨论）。如果！[](media/image69.wmf) 是对角矩阵，该技术等价于朴素贝叶斯（读者可以思考为什么？）。

我们可以使用下式来实现对一个特征向量的分类，由式 2.11 推理得到：

![](media/image70.wmf) （4.30）

当我们基于每个类条件概率密度函数计算 x 的概率密度时，必须测量 x 到每个类中心！[](media/image71.wmf) 的马氏距离。所以这种方法又被认为是最近质心分类器（nearest centroids classifier）。

![C:\\Users\\Administrator\\AppData\\Local\\Microsoft\\Windows\\Temporary Internet Files\\Content.MSO\\AA29106D.tmp](media/image72.png){width="5.616000656167979in" height="3.0505238407699036in"}

（a） （b）

图 4.2. （a）身高/体重数据；（b）针对每个类别训练的 2 维高斯分布的可视化，在椭圆中包含 95%的概率质量。图形由程序 gaussHeightWeight 生成。

举例来说，图 4.2 展示了 2 个在 2 维空间中的高斯类条件概率密度函数，分别代表男人和女人的身高和体重。我们可以发现，两个特征是相关的，这与我们的直觉是一致的（高的人胖的可能性更高）。图中每个类的高斯分布边际线（图中椭圆）包含了 95%的概率质量。如果我们拥有一个均匀的类先验概率分布，我们可以使用下式对一个新的样本 x 进行分类：

![](media/image73.wmf) （4.31）

![H:\\Work Files\\MLAPP_CODE\\MLAPP-C4-Code\\4.3a.png](media/image74.png){width="2.862070209973753in" height="2.60799978127734in"}![H:\\Work Files\\MLAPP_CODE\\MLAPP-C4-Code\\4.3b.png](media/image75.png){width="2.8523031496062994in" height="2.576000656167979in"}

图 4.3 2 分类和 3 分类情况下的二次判别模型可视化。图形由程序 discrimAnalysisDboundariesDemo 生成。

4.2.1 二次判别分析

关于类标签 $y$ 的后验分布由式 2.11 给出，通过引入高斯分布的定义，我们可以对这个模型进行更加深入的探讨，如下所示：

![](media/image76.wmf) （4.32）

对上式化简后的函数是关于 x 的二次函数。这个结果被称为二次判别分析（quadratic discriminant analysis，QDA）。图 4.3 给出了一些在 2 维空间中类与类之间决策边界的形状。

4.2.2 线性判别分析

现在我们考虑一个特殊的情况，在这种情况中，协方差矩阵在不同的类之间共享（shared），即！[](media/image77.wmf)。此时，我们可以对式 4.32 进行化简：

![](media/image78.wmf) （4.33）

![](media/image79.wmf) （4.34）

如果我们令

![](media/image80.wmf) （4.35）

![](media/image81.wmf) （4.36）

我们有：

![](media/image82.wmf) （4.37）

其中！[](media/image83.wmf)，为 softmax 函数，定义为：

![](media/image84.wmf) （4.38）

Softmax 函数之所以叫"softmax"是因为它的性能与 max 函数十分相似（译者注：从字面上理解就是比较光滑（soft）的 max 函数）。为了说明这一点，将！[](media/image85.wmf) 中的每个分量！[](media/image86.wmf) 除以常量* T*，该常量被称为温度（temperature）。当！[](media/image87.wmf) 时，我们发现：

![](media/image88.wmf) （4.39）

![C:\\Users\\Administrator\\AppData\\Local\\Microsoft\\Windows\\Temporary Internet Files\\Content.MSO\\202F342D.tmp](media/image89.png){width="6.04in" height="1.5823545494313211in"}

图 4.4 不同温度下的 Softmax 分布！[](media/image90.wmf)，其中！[](media/image91.wmf)。当温度比较高时（左图），分布是比较均匀的，然而当温度比较低时（右图），分布会变得比较"尖"，它将所有的概率质量都集中在了最有可能的那个状态上。图形由程序 softmaxDemo2 生成。

换句话说，当温度比较低时，分布在所有时刻都处在最有可能的状态，然而，当温度变高时，分布所处的状态会比较均匀。图 4.4 说明了这个原理。值得注意的是，softmax 这个术语来自于统计物理学领域，在该领域，一般使用玻尔兹曼分布（Boltzmann distribution），它与 softmax 函数的形式一样。

![H:\\Work Files\\MLAPP_CODE\\MLAPP-C4-Code\\4.5a.png](media/image92.png){width="2.8493821084864392in" height="2.56in"}![H:\\Work Files\\MLAPP_CODE\\MLAPP-C4-Code\\4.5b.png](media/image93.png){width="2.855999562554681in" height="2.5566152668416446in"}

图 4.5 2 分类和 3 分类情况下的线性判别模型可视化。图形由程序 discrimAnalysisDboundariesDemo 生成。

式 4.37 的一个有趣性质是，如果对该式取对数，我们将得到一个关于 x 的线性函数。所以在类* c *和！[](media/image94.wmf) 之间的决策边界是一条直线。因此这个技术被称为线性判别分析（linear discriminant analysis，LDA）。这条决策边界的形式可由下式导出：

![](media/image95.wmf) （4.40）

![](media/image96.wmf) （4.41）

![](media/image97.wmf) （4.42）

图 4.5 展示了一些案例。

一种训练 LDA 模型并且利用这个模型推理类标签后验分布的替代方案是直接训练！[](media/image98.wmf) 中的权重矩阵 W，该矩阵的尺寸大小为* C*× $\mathcal{D}$ 。这被称为多类别逻辑回归（multi-class logistic regression），或者多项式逻辑回归（multinomial logistic regression）。我们将会在 8.2 节讨论这个模型的细节，同时在 8.6 节解释两种方法的区别。

4.2.3 二分类 LDA

为了更加深入地理解这些公式的含义，让我们从简单的二分类问题开始分析。在这种情况下，后验分布为：

![](media/image99.wmf) （4.43）

![](media/image100.wmf) （4.44）

其中！[](media/image101.wmf) 为 sigmoid 函数（式 1.10）。

式中：

![](media/image102.wmf) （4.45）

![](media/image103.wmf) （4.46）

所以，我们定义：

![](media/image104.wmf) （4.47）

![](media/image105.wmf) （4.48）

然后，我们有！[](media/image106.wmf)，因此，我们有：

![](media/image107.wmf) （4.49）

（上式与逻辑回归十分相关，我们将在 8.2 节对逻辑回归进行讨论。）所以最终的决策规则采用如下的方式得到：考虑向量（x- x~0~），将该向量在方向 w 上进行投影（即内积），观察内积的正负结果。

![](media/image108.png){width="2.4879997812773404in" height="2.205673665791776in"}

图 4.6 2 分类问题的 LDA，其中！[](media/image109.wmf)

如果！[](media/image110.wmf)，则 w 的方向为！[](media/image111.wmf)。所以我们对某个点的分类只要考虑向量（x- x~0~）的投影是靠近！[](media/image112.wmf) 还是！[](media/image113.wmf)。这个过程如图 4.6 所示。进一步，如果！[](media/image114.wmf)，则！[](media/image115.wmf)，即向量！[](media/image112.wmf) 和！[](media/image113.wmf) 连线的中点。如果我们令！[](media/image116.wmf)，则 x~0~靠近！[](media/image112.wmf)（译者注：可以观察式 4.48 的变化），所以大部分的线段属于类 1。相反，如果！[](media/image117.wmf)，则边界将右移。因此我们发现类的类先验分布！[](media/image118.wmf) 只是改变决策的阈值，但不会改变决策边界整体的几何形状，正如我们在前面所声明的。（一个相似的讨论同样应用在多分类情况中。）

w 的幅值决定了逻辑斯特函数 sigm 的陡峭程度，取决于期望相较于方差的可分离程度有多高。在心理学和信号检测理论中，通常使用物理量 d-prime 来定义一个信号在有噪音的背景中的可判别性（discriminability）：

![](media/image119.wmf) （4.50）

其中！[](media/image120.wmf) 为信号的期望，![](media/image121.wmf) 为噪声的期望，![](media/image122.wmf) 表示噪音的标准差。如果！[](media/image123.wmf) 很大，那么信号可以更容易的从噪声中判别出来。

4.2.4 判别分析的 MLE

现在我们讨论如何训练一个判别分析模型。最简单的方式是使用极大似然法。判别分析的对数似然函数为：

![](media/image124.wmf) （4.51）

不难发现上式分解成一个包含参数！[](media/image125.wmf) 的项和* C *个分别包含参数！[](media/image126.wmf) 的项。因此我们对这些参数进行单独的优化。对于类先验分布！[](media/image125.wmf)，我们有！[](media/image127.wmf)，这一点与朴素贝叶斯分类器是一致的。对于类条件概率密度，我们仅仅根据特征向量所属的类别将它们归类，然后对每个类高斯分布参数进行极大似然估计：

![](media/image128.wmf) （4.52）

我们在程序 discrimAnalysisFit 中对上述训练过程中给出了 python 实现。

4.2.5 克服过拟合的策略

MLE 方法的速度和简单性是它最大的吸引力之一。然而，MLE 对于高维数据会出现严重的过拟合。特别的，当！[](media/image129.wmf)，完全协方差矩阵的 MLE 是一个奇异矩阵（译者注：作为一个思考题，读者可以试着证明之）。就算！[](media/image130.wmf)，完全协方差矩阵也是病态的，意味着它接近奇异矩阵。有几种可能的方法用于解决这个问题：

-   对每个类使用对角协方差矩阵，即假设每个特征之间是条件独立的。这种情况等价于一个朴素贝叶斯分类器（在 3.5 节中介绍）；

-   使用一个完全协方差矩阵，但是强制每个协方差矩阵都相同，即！[](media/image131.wmf)。这是参数绑定（parameter tying）或者参数共享（parameter sharing）的应用之一，最终的模型等价于 LDA（4.2.2 节）。

-   使用一个对角协方差矩阵，并且强制它共享。这被称为对角协方差 LDA，将在 4.2.7 节进行讨论。

-   使用一个完全协方差矩阵，但是为其添加一个先验分布，并最终进行积分。如果我们使用一个共轭先验，这个结果将会是一个闭合的形式，其结果将在 4.6.3 讨论；这种方法与"贝叶斯方法下的朴素贝叶斯"方法（3.5.1.2 节中介绍）类似。

-   通过 MAP 估计方法训练一个完全或者对角协方差矩阵。我们将会在下文讨论两种不同的先验分布。

-   将数据投影到一个低维空间，再进行高斯分布的训练。章节 8.6.3.3 将介绍一种方式，从而找到最佳（最具判别性的）的线性投影。

我们将在后文讨论这些方案。

4.2.6 含正则项的 LDA\*

假设我们对协方差矩阵实行参数共享，即！[](media/image131.wmf)，这就是在 LDA 中使用的方法。更进一步的，我们使用一个逆威舍特（Wishart）先验分布！[](media/image132.wmf)（详见 4.5.1 节）。然后得到关于！[](media/image133.wmf) 的 MAP 估计：

![](media/image134.wmf) （4.53）

其中参数！[](media/image135.wmf) 控制着正则化的强弱程度，它与先验分布的强度！[](media/image136.wmf) 有关（见 4.6.2.1 介绍更多的细节）。这个技术被称为正则化判别分析（regularized discriminant analysis，RDA）。

当我们需要计算一个样本的类条件概率密度时，我们需要计算！[](media/image137.wmf)，也就是！[](media/image138.wmf)，当 $\mathcal{D}$ \>*N *时，![](media/image138.wmf) 根本无法计算。然而我们可以使用设计矩阵 X（译者注：由所有样本特征组成的设计矩阵，大小为* N*× $\mathcal{D}$ ）的 SVD（奇异值分解，见 12.2.3 节）来解决这个问题，这一点我们在后面介绍（注意这种方式不能用在 QDA，因为它不是关于 x 的线性函数）。

令！[](media/image139.wmf) 为设计矩阵的 SVD，其中 V 的大小为 $\mathcal{D}$ ×*N*，U 为* N*×*N *的正交矩阵，D 为尺寸为* N *的对角矩阵。更进一步，定义尺寸为* N*×*N *的矩阵 Z=UD。这类似于一个在低维空间中的设计矩阵（因为我们假设* N*\< $\mathcal{D}$ ）。同样，我们定义！[](media/image140.wmf) 作为在低维空间中的数据的期望，我们可以使用！[](media/image141.wmf) 实现对原来高维空间中的期望的还原，因为！[](media/image142.wmf)（译者注：原文为！[](media/image143.wmf)）。基于这些定义，我们可以重写！[](media/image144.wmf) 的 MLE：

![](media/image145.wmf) （4.54）

![](media/image146.wmf) （4.55）

![](media/image147.wmf) （4.56）

![](media/image148.wmf) （4.57）

![](media/image149.wmf) （4.58）

其中！[](media/image150.wmf) 为矩阵 Z 的经验协方差矩阵。因此我们可以将 MAP 估计写成：

![](media/image151.wmf) （4.59）

![](media/image152.wmf) （4.60）

值得注意的是，实际上我们并不需要计算 $\mathcal{D}$ × $\mathcal{D}$ 的矩阵！[](media/image153.wmf)。因为从式 4.38 中我们发现，使用 LDA 进行分类时，我们需要做的只是计算！[](media/image154.wmf)，其中

![](media/image155.wmf) （4.61）

对于 RDA 方法而言，我们在计算重要的！[](media/image156.wmf) 项时不需要计算 $\mathcal{D}$ × $\mathcal{D}$ 的矩阵：

![](media/image157.wmf) （4.62）

其中！[](media/image158.wmf) 为属于类* c *的矩阵 Z 的期望。可参考程序 rdaFit。

4.2.7 对角 LDA

一种替代 RDA 的简单方法是共享协方差矩阵，正如在 LDA 中的那样，令！[](media/image131.wmf)。然后对于每个类使用对角协方差矩阵。这被称为对角 LDA（diagonal LDA）模型，等价于！[](media/image159.wmf) 时的 RDA。对应的判别式函数为（对比式 4.32）：

![](media/image160.wmf) （4.63）

一种典型的情况是令！[](media/image161.wmf) 和！[](media/image162.wmf)，其中！[](media/image163.wmf) 被称为特征* j *的混合经验方差（pooled empirical variance），定义为：

![](media/image164.wmf) （4.64）

在高维数据中，这个模型的效果比 LDA 和 RDA 要好。

4.2.8 最近收缩质心分类器、*

对角 LDA 的一个缺点在于它依赖于所有的特征。在高维数据的问题中，出于精度和可解释性的原因，我们可能更倾向于只使用全部特征的一个子集。一种方法是使用特征筛选，这种方法可以基于 3.5.4 节所描述的互信息。我们现在讨论另一种解决这个问题的方法：最近收缩质心（nearest shrunken centroids）分类器。

该方法的基本思想是基于一个促进模型稀疏化的先验分布（Laplace 先验分布），对对角 LDA 进行 MAP 估计（见 13.3 节）。更加精确的表达为，定义特定类下某个特征的期望！[](media/image165.wmf) 为一个与类无关的特征期望！[](media/image166.wmf) 和一个与类相关的偏置量！[](media/image167.wmf) 的组合：

![](media/image168.wmf) （4.65）

![H:\\Work Files\\MLAPP_CODE\\MLAPP-C4-Code\\shrunkenCentroidsSRBCTdemo\\Figure_1.png](media/image169.png){width="3.584266185476815in" height="2.8079997812773403in"}

图 4.7 在最近收缩质心模型中，误分类率与收缩程度！[](media/image170.wmf) 之间的关系，上述模型的数据为 SRBCT 基因表达数据。图形由程序 shrunkenCentroidsSRBCTdemo 生成。

![H:\\Work Files\\MLAPP_CODE\\MLAPP-C4-Code\\shrunkenCentroidsSRBCTdemo\\Figure_1-1.png](media/image171.png){width="2.816000656167979in" height="2.3938779527559055in"}![H:\\Work Files\\MLAPP_CODE\\MLAPP-C4-Code\\shrunkenCentroidsSRBCTdemo\\Figure_1-2.png](media/image172.png){width="2.8159995625546808in" height="2.3839031058617675in"}

![H:\\Work Files\\MLAPP_CODE\\MLAPP-C4-Code\\shrunkenCentroidsSRBCTdemo\\Figure_1-3.png](media/image173.png){width="2.8159722222222223in" height="2.3729680664916883in"}![H:\\Work Files\\MLAPP_CODE\\MLAPP-C4-Code\\shrunkenCentroidsSRBCTdemo\\Figure_1-4.png](media/image174.png){width="2.8319991251093612in" height="2.3869892825896764in"}

图 4.8 通过交叉验证得到的最优参数！[](media/image170.wmf)=4.6（原文为 4.4），基于该最优模型绘制的收缩质心。其中与类别相关的特征共 50 个（原文为 39 个）。图形由程序 shrunkenCentroidsSRBCTdemo 生成。

我们将会为！[](media/image167.wmf) 赋予一个先验分布，该先验分布将鼓励！[](media/image167.wmf) 中的某些元素严格为零，并基于该先验分布进行最大后验估计。如果对于特征* j*，在所有类* c *中，我们有！[](media/image175.wmf)，则特征* j *对于解决分类问题没有任何帮助（因为！[](media/image176.wmf) 将独立于类* c*）。所以那些不具备可判别性的特征将会被自动忽略。程序 shrunkenCentroidsFit 展示了上述过程。

让我们展示一个实际应用案例。考虑一个问题，在这个问题中，我们需要对一个基因表达数据库进行分类，该数据库中有 2308 个基因，共分为 4 个类别，63 个训练样本和 20 个测试样本。使用对角 LDA 分类器在测试集上将产生 5（原文中也为 5 个）个错误。对于一定范围内的！[](media/image177.wmf) 值，使用最近收缩质心分类器在测试集上的误分类率为 0，如图 4.7 所示。更为重要的是，该模型是稀疏的，所以更加具备可解释性，图 4.8 用灰色曲线绘制了不含惩罚项的！[](media/image167.wmf) 的估计值，同时用蓝色曲线绘制了！[](media/image167.wmf) 的收缩估计值（含惩罚项）。（这些估计值使用通过交叉验证估计出来的最优！[](media/image177.wmf) 值进行计算。）我们发现只有 50（原文中是 39 个）个基因被用来做分类任务，而非原来的 2308 个基因。

现在考虑一个更加困难的问题，我们有 16603 个基因，训练集包含 144 个病人，测试集包含 54 个病人，以及 14 个不同种类的癌症。Hastie 等人指出最近质心收缩分类器只使用 6520 个基因，在测试集上产生 17 个误差；RDA（4.2.6 节）使用 16603 个基因，其在测试集上产生 12 个误差。程序 cancerHighDimClassifDemo 可以用来产生这些数字。

4.3 联合高斯分布中的推理问题

给定一个联合分布* p*(x~1~,x~2~)，如果能够计算边缘概率分布* p*(x~1~) 和条件概率分布* p*(x~1~\|x~2~) 将会是一件十分有用的事。我们将会在下文中进行讨论，并且给出一些具体的应用。这些运算在最坏情况下的时间复杂度为* O*( $\mathcal{D}$ ^3^)。20.4.3 节会给出更快的方法。

4.3.1 相关结论

定理 4.3.1 （MVN 的边缘和条件分布）。假设 x=\[x~1~,x~2~\] 为具备如下参数的联合高斯分布：

![](media/image178.wmf) （4.66）

其边缘概率分布为：

![](media/image179.wmf) （4.67）

其后验条件分布为：

（4.68）

式 4.68 在本书中是十分重要的结论，所以我们使用方框将其框出，这样你就可以很容易找到它，关于它的证明请参考 4.3.4 节。

不难发现，无论是边缘概率还是条件概率分布，其本身都还是高斯分布。对于边缘概率分布，我们仅仅只是提取了对应于 x~1~或 x~2~的参数。对于条件概率分布，我们需要做更多的工作。然而，它并没有想象中的那么复杂：对于条件概率分布的期望，它是关于 x~2~的线性函数，条件概率分布的协方差矩阵是一个与 x~2~无关的常数矩阵。我们给出关于后验期望的三种（等价的）表达式，以及协方差矩阵的两种（等价的）表达式，每一种表达方式在不同的情况下都有各自的用处。

4.3.2 例子

接下来，我们将给出上式的一些实际应用，从而使得这些结论更加的直观。

![H:\\Work Files\\MLAPP_CODE\\MLAPP-C4-Code\\PIC\\4.9.png](media/image181.png){width="5.679666447944007in" height="1.896000656167979in"}

（a） （b） （c）

图 4.9 （a）联合高斯分布* p*( $x$ ~1~, $x$ ~2~)，相关系数为 0.8。图中我们绘制了 95%概率质量的等高线和主轴。（b）非条件边缘分布* p*(x~1~)。（c）条件概率分布* p*( $x$ ~1~\| $x$ ~2~)=( $x$ ~1~\|0.8,0.36)。图形由程序 gaussCondition2Demo2 生成。

4.3.2.1 2 维高斯分布的边缘分布和条件分布

让我们考虑一个在 2 维空间中的例子。其协方差矩阵为：

![](media/image182.wmf) （4.69）

边缘分布* p*( $x$ ~1~) 为一个 1 维高斯分布，其获得的方式是将 2 维高斯分布投影到 $x$ ~1~轴上：

![](media/image183.wmf) （4.70）

假设我们观察到了* X*~2~= $x$ ~2~；其条件概率分布* p*( $x$ ~1~\| $x$ ~2~) 的获取方式是通过直线* X*~2~= $x$ ~2~对联合概率分布进行"切片"（如图 4.9 所示）：

![](media/image184.wmf) （4.71）

如果！[](media/image185.wmf)，我们得到：

![](media/image186.wmf) （4.72）

在图 4.9 中我们展示了当！[](media/image187.wmf) 时， $x$ ~2~=1 例子。我们发现！[](media/image188.wmf)，这与直觉上是一致的，因为！[](media/image189.wmf)，意味着如果 $x$ ~2~基于它的期望（![](media/image190.wmf)）增长 1，那么 $x$ ~1~基于它的期望（![](media/image191.wmf)）的增长为 0.8。我们同时发现！[](media/image192.wmf)。这与直觉上也是一致的：通过观察到 $x$ ~2~值，我们关于 $x$ ~1~的不确定度会下降，因为我们已经学习到了一些关于 $x$ ~1~的知识。如果！[](media/image193.wmf)，我们将得到！[](media/image194.wmf)，因为如果 $x$ ~2~与 $x$ ~1~不相关（因此互相独立，译者注：此处应该是不存在线性关系），那么 $x$ ~2~并不会涵盖关于 $x$ ~1~的任何信息。

4.3.2.2 无噪数据的插值

假设我们需要估计一个 1 维函数，其定义域为、[0,*T*\]，该函数在* N *个观察点* t*~i~处满足！[](media/image195.wmf)。现在假设观察到的数据是无噪的，我们需要对这些数据进行插值（interpolate），即：我们需要拟合一条函数，这个函数精确地通过这些观测点（4.4.2.3 将介绍含噪数据的情况）。问题在于：函数在观察到的数据点之间的行为是什么样的呢？通常情况下，"未知函数是光滑的"这一假设是比较合理的。在第 15 章，我们将看到如何为函数赋予先验分布，并且根据观察到的数据去更新这个先验分布，从而得到关于函数的后验分布。但在本节，我们采用一个更加简单的方式，对于那些定义在 1 维空间上的函数而言，利用插值法计算出来的函数作为最大后验估计是合适的。

我们首先对这个问题进行形式化描述。我们将该函数的支撑集（定义域）分成 $\mathcal{D}$ 的相等的区间。然后我们定义：

![](media/image196.wmf) （4.73）

通过假设* x~j~*为相邻两个点* x~j-1~*和* x~j+1~*的均值，外加一些高斯噪音，我们实现了之前"函数是光滑的"这一先验假设：

![](media/image197.wmf) （4.74）

其中！[](media/image198.wmf)。精度项！[](media/image199.wmf) 控制着我们所认为的这个函数的变化范围：当！[](media/image199.wmf) 比较大时，则代表我们相信这个函数非常光滑，当！[](media/image199.wmf) 比较小时，则我们认为这个函数相当扭曲。使用向量的表达形式，上式可以被写成：

![](media/image200.wmf) （4.75）

其中 L 为尺寸等于（ $\mathcal{D}$ -2）× $\mathcal{D}$ 的二阶有限差分矩阵（finite difference matrix）：

![](media/image201.wmf) （4.76）

相应的先验分布具备如下形式：

![](media/image202.wmf) （4.77）

在后面的内容中，我们假设矩阵 L 已按照比例！[](media/image199.wmf)（译者注：个人觉得应该是！[](media/image203.wmf)）增长，所以在后面的内容中将忽略！[](media/image199.wmf) 项，仅仅书写！[](media/image204.wmf) 作为精度矩阵。

值得注意的是，尽管 x 为 $\mathcal{D}$ 维向量，而精度矩阵！[](media/image205.wmf) 的秩仅为 $\mathcal{D}$ -2（读者可以自行验证）。所以这不是一个合适的先验分布，而这种情况对应于一个内在的高斯随机场（19.4.4 节给出更多信息）。然而，如果我们观察到* N* ≥ 2 个数据点，则相应的后验分布是合理的。

现在我们令 x~2~为* N *个已知的无噪音函数观测值，x~1~为 $\mathcal{D}$ -*N *个未知的函数值。不失一般性，假设未知变量被排在前面，其次是观测变量。这样我们就可以将矩阵 L 拆分成：

![](media/image206.wmf) （4.78）

同样，我们将联合分布的精度矩阵拆分成：

![](media/image207.wmf) （4.79）

使用式 4.68，我们可以将条件概率分布写成：

![](media/image208.wmf) （4.80）

![](media/image209.wmf) （4.81）

![](media/image210.wmf) （4.82）

值得注意的是，通过求解下面的线性方程组，我们可以得到期望值：

![](media/image211.wmf) （4.83）

![H:\\Work Files\\MLAPP_CODE\\MLAPP-C4-Code\\PIC\\4.10a.png](media/image212.png){width="2.696000656167979in" height="2.1440244969378828in"}![H:\\Work Files\\MLAPP_CODE\\MLAPP-C4-Code\\PIC\\4.10b.png](media/image213.png){width="2.87200021872266in" height="2.1412106299212597in"}

（a） （b）

图 4.10 对无噪音数据进行插值，其中高斯先验分布的精度为！[](media/image199.wmf)。（a）![](media/image199.wmf)=30.（b）![](media/image199.wmf)=0.01。图形由程序 gaussInterDemo 生成。

这种方式是有效的，因为 L~1~是一个三对角矩阵。图 4.10 给出了这些方程的说明。我们发现，后验期望值！[](media/image214.wmf) 在特定的点等于观测到的值，并且在观测值之间实现了平滑插值，这一点与我们的目标是一致的。

绘制出每个点的边缘置信区间（pointwise marginal credibility intervals）![](media/image215.wmf) 是一件很有趣的事情，这个置信区间用灰色区域表示。不难发现，当我们离开那些观测数据点时，方差变大。同时，当我们降低先验分布的精度！[](media/image199.wmf) 时，其方差也会增加。有趣的是，![](media/image199.wmf) 的值并不会对后验分布的期望值有影响，因为它在乘上！[](media/image216.wmf) 和！[](media/image217.wmf) 时，![](media/image199.wmf) 的影响被消除了。相反，如果我们考虑观测到的是含噪数据点，正如在 4.4.2.3 中所介绍的，我们将会发现先验分布的精度对后验分布期的望值估计值也有影响。

边缘置信区间并不能捕捉到如下事实：相邻的点是相关的。为了说明这一点，我们可以后验分布中采样出完整的函数（比如向量 x），并且绘制这个函数曲线。这些曲线在图 4.10 中以比较细的曲线显示。这些曲线相较于后验分布的期望值来说并没有那么光滑。因为在先验分布中，我们仅仅惩罚了一阶差分。关于这一点，我们会在 4.4.2.3 中进行进一步的讨论。

![H:\\Work Files\\MLAPP_CODE\\MLAPP-C4-Code\\PIC\\4.11.png](media/image218.png){width="5.835779746281715in" height="3.1580872703412073in"}

图 4.11 数据重构的示意图。左侧：相关行中观测到的数据点；第 2 列：数据重构后的后验预测期望；第 3 列：真实的数据；第 4 列：真实数据与重构数据的偏差；第 5 列：后验预测的不确定度。（图形由程序 gaussImputationDemo 生成）

4.3.2.3 数据重构

假设我们在一个设计矩阵中缺失了一些数据项。如果列与列（即变量与变量）之间是相关的，那么我们可以使用看到的数据去预测缺失的数据。图 4.11 展示了一个简单的例子。我们从一个 20 维的高斯分布中采样得到一些数据，然后在每一行故意"隐藏"50%的数据。然后根据观察到的数据，使用真实的（生成）模型，去推理那些缺失的数据。更加精确的表达是，对于每一行 $i$ ，我们计算！[](media/image219.wmf)，其中！[](media/image220.wmf) 和！[](media/image221.wmf) 为在样例 $i$ 中观测值和隐藏值的索引值。基于！[](media/image219.wmf)，我们计算每个缺失变量的边缘分布！[](media/image222.wmf)。然后绘制出该分布的期望！[](media/image223.wmf)；从最小化我们的期望方差角度而言，该值表示我们对这个缺失项的真实值的最佳猜测（5.7 节给出更多细节）。图 4.11 说明预测的值与真实值十分接近。（当然，如果！[](media/image224.wmf)，则期望值等于观测值！[](media/image225.wmf)）

我们可以使用！[](media/image226.wmf) 作为对我们猜测值的不确定度的衡量，尽管在图中这一点并没有展示（译者注：我们在图 4.11 的第 5 列展示了这一点）。另一个可选的方案是，我们可以从分布！[](media/image227.wmf) 采集多个样本，这被称为多重重构（multiple imputation）。

除了对那些缺失值进行重构，我们可能对计算每一行中那些观测值的似然函数感兴趣！[](media/image228.wmf)，可以使用式 4.67 进行计算。这对检测异常值是有用的（非典型应用）。

4.3.3 MVN 的信息表达形式

假设！[](media/image229.wmf)。我们可以知道！[](media/image230.wmf) 为期望向量，![](media/image231.wmf) 为协方差矩阵。这些被称为该分布的矩参数（moment parameters）。然而，有些时候使用典范参数（canonical parameters）或者自然参数（natural parameters）是有用的，定义为：

![](media/image232.wmf) （4.84）

我们可以使用下式实现矩参数的转换：

![](media/image233.wmf) （4.85）

（关于上述的两个典范参数我们将在 9.2 节讨论更多的细节，那个时候我们将讨论指数族分布。）

使用典范参数，我们可以将 MVN 写成信息形式（information form）（又被称为典范形式 canonical form）：

![](media/image234.wmf) （4.86）

其中我们使用符号！[](media/image235.wmf) 以区别于矩参数形式！[](media/image236.wmf)。

同样，我们也可以推导出信息形式的边缘和条件概率分布。我们发现：

![](media/image237.wmf) （4.87）

![](media/image238.wmf) （4.88）

所以我们发现矩形式下的边缘分布更加容易，而信息形式下的条件分布更加容易。

当我们采用信息形式时，有一个操作也变得非常的容易，即：两个高斯分布相乘。我们有：

![](media/image239.wmf) （4.89）

然而，在矩参数形式下，事情会变得比较麻烦：

![](media/image240.wmf) （4.90）

4.3.4 结果证明^\*^

现在我们讨论定理 4.3.1。对那些繁重的线性代数感到反感的读者可以安全地跳过这个章节。我们首先会推导一些我们会在本节或者书中其他地方使用到的结果。最后我们会回到证明本身。

4.3.4.1 利用舒尔补实现分块矩阵的逆

我们需要的关键工具是对一个分块矩阵求逆。利用下面的结果我们可以完成这一点。

定理 4.3.2 （分块矩阵的逆矩阵）。考虑一个一般形式的分块矩阵：

![](media/image241.wmf) （4.91）

其中我们假设 E 和 H 是可逆的。我们有

![](media/image242.wmf) （4.92）

![](media/image243.wmf) （4.93）

其中：

![](media/image244.wmf) （4.94）

![](media/image245.wmf) （4.95）

我们称！[](media/image246.wmf) 为矩阵 M 关于 H 的舒尔逆（Schur complement）。式 4.92 被称为分块求逆公式（partitioned inverse formula）。

证明：如果我们可以对矩阵 M 进行分块对角化，那么对矩阵 M 的求逆会变得更加容易。为了使矩阵 M 的右上角元素变成 0，我们进行如下的矩阵欲乘：

![](media/image247.wmf) （4.96）

相似的，为了使其左下角元素变成 0，我们进行如下的矩阵后乘：

![](media/image248.wmf) （4.97）

将上式放在一起，我们得到：

![](media/image249.wmf) （4.98）

对上式两边求逆：

![](media/image250.wmf) （4.99）

所以：

![](media/image251.wmf) （4.100）

将上式用相应的矩阵定义替换，得到：

![](media/image252.wmf) （4.101）

![](media/image253.wmf) （4.102）

![](media/image254.wmf) （4.103）

另一种可选方案是，将矩阵 M 分解为 E 和！[](media/image255.wmf) 项，得到：

![](media/image256.wmf) （4.104）

4.3.4.2 矩阵求逆引理

我们现在基于上述结果推理一些有用的引理。

引理 4.3.1 （矩阵求逆引理）。考虑一个一般的分块矩阵！[](media/image241.wmf)，我们假设 E 和 H 式可逆的。我们有：

![](media/image257.wmf) （4.105）

![](media/image258.wmf) （4.106）

![](media/image259.wmf) （4.107）

前两个等式被称为矩阵求逆引理（matrix inversion lemma）或者谢尔曼 - 莫里森 - 伍德伯里公式（Sherman-Morrison-Woodbury formula）。第三个等式被称为矩阵行列式引理（matrix determinant lemma）。在机器学习或者统计学中的一个典型应用如下。令！[](media/image260.wmf) 为* N*×*N *的对角矩阵，![](media/image261.wmf) 大小为* N*× $\mathcal{D}$ ，其中！[](media/image262.wmf)，令！[](media/image263.wmf)。然后我们有：

![](media/image264.wmf) （4.108）

等式的左边计算的时间复杂度为* O*(*N*^3^)，等式右边的时间复杂度为* O*( $\mathcal{D}$ ^3^)。

另一个相关的应用是计算一个逆矩阵的秩一矫正（rank one update）。令* H* = -1（一个标量），F = u（一个列向量），G = v^T^（一个行向量）。然后我们有：

![](media/image265.wmf) （4.109）

![](media/image266.wmf) （4.110）

当我们不断将一个数据向量添加到一个设计矩阵上，并且想更新我们的充分统计量时，上述的结论十分有用。

证明：为了证明等式 4.105，我们只需要简单的令式 4.92 和 4.93 的左上方分块相等即可。为了证明等式 4.106，我们只需要简单的令式 4.92 和 4.93 的右上方分块相等即可。读者可以试着证明式 4.107。

4.3.4.3 高斯条件分布公式的证明

现在回到我们最开始的目的，即证明等式 4.68。将联合概率分布* p*(x~1~,x~2~) 分解成* p*(x~1~) 和* p*(x~1~\|x~2~)：

![](media/image267.wmf) （4.111）

使用式 4.101，上式指数可以写成：

![](media/image268.wmf) （4.112）

![](media/image269.wmf) （4.113）

![](media/image270.wmf) （4.114）

![](media/image271.wmf) （4.115）

上式具备如下的形式：

exp（关于 x~1~和 x~2~的二次项）×exp（关于 x~2~的二次项） （4.116）

所以，我们成功地将联合分布因式分解为：

![](media/image272.wmf) （4.117）

![](media/image273.wmf) （4.118）

条件分布的参数可以从上面的等式中解析出来，为：

![](media/image274.wmf) （4.119）

![](media/image275.wmf) （4.120）

我们同样可以使用！[](media/image276.wmf) 来验证归一化常数是正确的：

![](media/image277.wmf) （4.121）

![](media/image278.wmf) （4.122）

其中* d*~1~=dim(x~1~)，*d*~2~=dim(x~2~)。

4.4 线性高斯系统

假设我们有两个变量 x 和 y。令！[](media/image280.wmf) 为隐变量，![](media/image281.wmf) 为变量 x 的含噪观测值。假设我们有如下的先验分布和似然函数：

（4.123）

其中矩阵 A 的大小为！[](media/image282.wmf)。上式是一个线性高斯系统（linear Gaussian system）的例子。用图示的方式表达为！[](media/image283.wmf)，意思是说 x 生成 y。本节我们将讨论如何逆转这个箭头，也就是说如何从 y 推测出 x。我们将在下文展示相关结论，并且给出一些案例，最后再给出这个结论的推导过程。在后面的章节中我们会看到这些结论的更多应用。

4.4.1 结果陈述

定理 4.4.1（线性高斯系统的贝叶斯法则）。给定一个线性高斯系统，如式 4.123 所述，其后验概率分布* p*(x\|y) 由下式给出：

（4.124）

除此之外，归一化常数* p*(y) 为：

（4.125）

证明过程见章节 4.4.3。

![H:\\Work Files\\MLAPP_CODE\\MLAPP-C4-Code\\PIC\\4.12.png](media/image286.png){width="5.783057742782153in" height="2.8326541994750656in"}

图 4.12 基于含噪观察值 y=3 的基础上进行的推理。（a）强先验！[](media/image287.wmf)，后验分布的期望值向先验分布的期望值 0 靠近。（b）弱先验分布！[](media/image288.wmf)。后验分布的期望与 MLE 相似。图形由程序 gaussInferParamsMean1d 生成。

4.4.2 例子

本节，我们将展示一些上述结果的应用。

4.4.2.1 从含噪的测量数据中预测一个未知标量

假设我们针对一个潜在量 $x$ 作出* N *个含噪的测量 $y$ ~i~；假设测量值的精度都是一样的，等于！[](media/image289.wmf)。所以，相应的似然函数为：

![](media/image290.wmf) （4.126）

假设未知真实值 $x$ 的先验分布为高斯分布：

![](media/image291.wmf) （4.127）

我们希望计算！[](media/image292.wmf)。为了在高斯分布中方便使用贝叶斯法则，我们将上述的形式进行改写，定义！[](media/image293.wmf)（一个 1×*N *的行向量，元素都为 1），![](media/image294.wmf)。然后我们有：

![](media/image295.wmf) （4.128）

![](media/image296.wmf) （4.129）

![](media/image297.wmf) （4.130）

这些等式十分符合我们的直观感受：后验精度！[](media/image298.wmf) 为先验精度！[](media/image299.wmf) 加上* N *个测量值的精度！[](media/image300.wmf)。同样，后验分布的期望！[](media/image301.wmf) 为最大似然估计！[](media/image302.wmf) 和先验期望！[](media/image303.wmf) 的凸组合。这就说明了后验分布的期望是在 MLE 和先验期望之间的一个权衡。如果相较于信号（即观测到的数据）的强度，先验较弱（![](media/image299.wmf) 相较于！[](media/image300.wmf) 较小），我们将赋予 MLE 更大的权重。如果先验相较于信号的强度较强（![](media/image299.wmf) 相较于！[](media/image300.wmf) 较大），我们将赋予先验更多的权重。这个过程在图 4.12 中进行展示，该图与图 3.6 中展示的 beta-binomial 分布十分相似。

值得注意的是，在后验分布的期望中包含项！[](media/image304.wmf)，所以拥有* N *个测试精度为！[](media/image300.wmf) 的测量值等价于拥有 1 个值为！[](media/image305.wmf)，精度为！[](media/image306.wmf) 的测量值。

我们将之前的结果利用后验分布的方差而非后验分布的精度进行重写：

![](media/image307.wmf) （4.131）

![](media/image308.wmf) （4.132）

![](media/image309.wmf) （4.133）

其中！[](media/image310.wmf) 表示先验分布的方差，![](media/image311.wmf) 表示后验分布的方差。

我们可以在每个观察值之后采用序列化的方式对后验分布进行更新。如果* N*=1，我们可以在观察到一个测量值之后重写后验分布（其中我们定义！[](media/image312.wmf) 分别为似然函数，先验分布和后验分布的方差）：

![](media/image313.wmf) （4.134）

![](media/image314.wmf) （4.135）

![](media/image315.wmf) （4.136）

我们可以用如下的三种形式重写后验分布的期望：

![](media/image316.wmf) （4.137）

![](media/image317.wmf) （4.138）

![](media/image318.wmf) （4.139）

第一个等式为先验分布期望和观测数据之间的凸组合。第二个等式表示先验期望向数据方向进行调整。第三个等式表示数据向先验期望进行调整，这被称为收缩（shrinkage）。这些等式是等价的，它们都说明后验分布在似然函数与先验分布之间的一种权衡。如果！[](media/image319.wmf) 相较于！[](media/image320.wmf) 小，即对应于一个更强的先验分布，那么收缩的程度将会很大（见图 4.12(a)）。然而，如果！[](media/image319.wmf) 相较于！[](media/image321.wmf) 大，即对应于一个更弱的先验分布，那么收缩的程度很小（见图 4.12(b)）。

另一种衡量收缩的程度的方式是使用信噪比（signal-to-noise ratio），定义为：

![](media/image322.wmf) （4.140）

其中！[](media/image323.wmf) 为真实的信号，![](media/image324.wmf) 为观测到的信号，![](media/image325.wmf) 为噪音项。

![H:\\Work Files\\MLAPP_CODE\\MLAPP-C4-Code\\PIC\\4.13.png](media/image326.png){width="5.660869422572178in" height="1.6444520997375327in"}

（a） （b） （c）

图 4.13 2 维高斯分布情况下的贝叶斯推理。（a）生成的数据服从分布！[](media/image327.wmf)，其中！[](media/image328.wmf)，![](media/image329.wmf)。我们假设传感器的协方差矩阵！[](media/image330.wmf) 已知，但是！[](media/image331.wmf) 未知。黑色的×代表！[](media/image331.wmf)。（b）先验分布！[](media/image332.wmf)。（c）在观察到 10 个数据之后的后验分布。图形由程序 gaussInferParamsMean2d 生成。

4.4.2.2 从含噪的测量数据中预测一个未知矢量

现在考虑* N *个向量观测值！[](media/image327.wmf) 和一个高斯先验分布！[](media/image333.wmf)。令！[](media/image334.wmf)，使用！[](media/image335.wmf) 表示精度为！[](media/image336.wmf) 的有效观测值，我们有：

![](media/image337.wmf) （4.141）

![](media/image338.wmf) （4.142）

![](media/image339.wmf) （4.143）

图 4.13 展示了一个在 2 维空间中的情况。我们可以将图中符号 x 当作一个目标在 2 维空间中正确但未知的坐标位置，比如一个导弹或者飞机，将！[](media/image340.wmf) 当作含噪的观测值，不如说雷达的"杂音"。当我们收到更多的雷达杂音，我们将更好地去定位真实的目标。在 18.3.1 节，我们将介绍如何扩展这个案例，利用著名的卡尔曼滤波算法实现对移动目标的追踪。

![H:\\Work Files\\MLAPP_CODE\\MLAPP-C4-Code\\PIC\\4.14a.png](media/image341.png){width="1.8964555993000876in" height="1.816000656167979in"}![H:\\Work Files\\MLAPP_CODE\\MLAPP-C4-Code\\PIC\\4.14b.png](media/image342.png){width="1.9343799212598425in" height="1.7920002187226596in"}![H:\\Work Files\\MLAPP_CODE\\MLAPP-C4-Code\\PIC\\4.14c.png](media/image343.png){width="1.903999343832021in" height="1.7671008311461067in"}

（a） （b） （c）

图 4.14 在我们观察到 y~1~=(0, -1)（红×）和 y~2~=(1, 0) 后（绿×）后进行的推理！[](media/image344.wmf)（黑×）。（a）相同精度的传感器，所以后验分布的期望值在两个圆圈之间；（b）传感器 2 更加可靠，所以估计值向绿色圆圈靠拢。（c）传感器 1 在垂直分量上更加可靠，传感器 2 在水平分量上更加可靠。估计值是两个测量值的一个组合。图形由程序 sensorFusion2d 生成。

现在假设我们有多个检测设备，我们需要将它们的信号组合起来。这种方式被称为传感器融合（sensor fusion）。如果不同的观测值之间具备不同的协方差（即不同设备的可靠度不同），那么后验预测将会是不同数据的加权平均。考虑图 4.14 中的案例，我们使用一个关于 x 的无信息先验分布，![](media/image345.wmf)。我们得到 2 个含噪观测值，![](media/image346.wmf) 和！[](media/image347.wmf)。然后，我们计算！[](media/image348.wmf)。

在图 4.14(a) 中，我们令！[](media/image349.wmf)，也就是说两个测试设备的可靠性是一致的。在这种情况下，后验期望在观测值 y~1~和 y~2~的连线中点处。在图 4.14(b) 中，我们令！[](media/image350.wmf)，即传感器 2 比传感器 1 更加可靠。在这种情况下，后验期望将更加接近 y~2~。在图 4.14(c) 中，我们令

![](media/image351.wmf)

所以传感器 1 在分量 $y$ ~2~上要比传感器 2 更加可靠（垂直方向），传感器 2 在分量 $y$ ~1~上要比传感器 1 更加可靠（水平方向）。在这种情况下，后验期望使用 y~1~的垂直分量和 y~2~的水平分量。

值得注意的是，这个技术关键之处在于它依赖于我们对每个传感器不确定度的建模。如果使用无加权的平均值进行计算将导致错误的结果。然而，我们已经假设每个传感器的精度已知。如果它们的不确定度未知，我们需要对不确定度！[](media/image352.wmf) 和！[](media/image353.wmf) 进行建模。章节 4.6.4 将介绍更多细节。

![H:\\Work Files\\MLAPP_CODE\\MLAPP-C4-Code\\PIC\\4.15a.png](media/image354.png){width="2.727263779527559in" height="2.0719991251093615in"}![H:\\Work Files\\MLAPP_CODE\\MLAPP-C4-Code\\PIC\\4.15b.png](media/image355.png){width="2.8162226596675417in" height="2.0480008748906386in"}

（a） （b）

图 4.15 含噪数据的插值（噪音方差等于 1）。（a）![](media/image356.wmf)=30；（b）![](media/image356.wmf)=0.01. 图形由程序 gaussInterpNoisyDemo 生成。

4.4.2.3 含噪数据的插值

我们现在重新考虑章节 4.3.2.2 中介绍的案例。此刻我们不再假设观测值是无噪声的。取而代之的是，假设我们有* N *个含噪的观测值 $y$ ~i~；不失一般性，假设观测值对应的真实值分别对应 $x$ ~1~,...,*x~N~*。我们使用线性高斯系统对这种情况进行建模：

![](media/image357.wmf) （4.145）

其中！[](media/image358.wmf)，![](media/image359.wmf) 为观测噪音，A 为* N*× $\mathcal{D}$ 的投影矩阵，它用于选择哪些值是观测值。比如说，如果* N*=2， $\mathcal{D}$ =4，我们有：

![](media/image360.wmf) （4.146）

像之前一样，我们使用一个不合适的先验分布，令！[](media/image361.wmf)，我们可以很容易地计算出后验分布的期望和方差。在图 4.15 中，我们绘制了后验分布的期望，方差和一些从后验分布中采样的样本。现在我们发现先验分布精度！[](media/image356.wmf) 对后验分布期望和方差都有影响。特别的，对于一个强先验（![](media/image356.wmf) 较大），估计值将会很平滑，不确定度很低。但对于一个弱先验（![](media/image356.wmf) 较小），估计值很扭曲，不确定度（远离观测值的）会很高。

后验期望也可以通过解决下面的优化问题实现求解：

![](media/image362.wmf) （4.147）

其中为了符号上书写便捷，我们定义 $x$ ~0~= $x$ ~1~和* x~D~*~+1~=*x~D~*。上述优化问题是如下问题的一个离散化近似：

![](media/image363.wmf) （4.148）

其中！[](media/image364.wmf) 为函数* f *的一阶导。第一项衡量了对数据的拟合程度，第二项惩罚那些过于扭曲的函数。这是吉洪诺夫正则化（Tikhonov regularization）的一个例子，它是泛函数据分析（functional data analysis）中的一个著名方式。第 15 章将给出更加复杂的方法，它们将实现更高的阶平滑度（所以最终的样本不再那么呈现锯齿状）。

4.4.3 结果的证明^\*^

现在我们推导公式 4.124。其基本思想是推导联合概率分布！[](media/image365.wmf)，然后使用 4.3.1 节介绍的结果去计算* p*(x\|y)。

更多的细节我们将在下面展示。联合概率分布的对数为（舍去那些无关的常数项）：

![](media/image366.wmf) （4.149）

这显然是一个联合高斯分布，因为它是二次项形式的指数。

将二次项中包含 x 和 y 的项展开，忽略那些线性项和常数项，我们有：

![](media/image367.wmf) （4.150）

![](media/image368.wmf) （4.151）

![](media/image369.wmf) （4.152）

其中联合分布的精度矩阵定义为：

![](media/image370.wmf) （4.153）

根据式 4.68，使用事实！[](media/image371.wmf)，我们有：

![](media/image372.wmf) （4.154）

![](media/image373.wmf) （4.155）

![](media/image374.wmf) （4.156）

![](media/image375.wmf) （4.157）

4.5 拓展：威舍特分布、*

威舍特分布是伽玛分布（译者注：伽玛分布的支撑集为{ $x$ \| $x$  \> 0}）向正定矩阵的一种泛化。相关书籍指出"在多变量统计领域中，从重要性和实用性来说，威舍特分布仅次于（多变量）正态分布"。我们将使用该分布来对协方差矩阵！[](media/image376.wmf) 或者它们的逆矩阵！[](media/image377.wmf) 的不确定度进行建模。

威舍特分布的概率密度函数定义为：

![](media/image378.wmf) （4.158）

其中！[](media/image379.wmf) 表示"自由度"，S 表示"尺度矩阵"。（我们不久将会对这些参数给出直观的感受。）该分布的归一化常数（需要对所有对称的正定矩阵进行积分）为下面那个令人生畏的表达式：

![](media/image380.wmf) （4.159）

其中！[](media/image381.wmf) 表示多变量伽玛函数（multivariate gamma function）：

![](media/image382.wmf) （4.160）

所以！[](media/image383.wmf)，且

![](media/image384.wmf) （4.161）

归一化常数只在！[](media/image385.wmf) 时存在（所以概率密度函数也只在这种情况下是被良好定义的）。

威舍特分布与高斯分布之间存在一定的关联。特别的，令！[](media/image386.wmf)，则散步矩阵！[](media/image387.wmf) 服从威舍特分布：![](media/image388.wmf)。因此，![](media/image389.wmf)。更一般的情况，威舍特分布！[](media/image390.wmf) 的期望和众数为：

![](media/image391.wmf) （4.162）

其中众数只在！[](media/image392.wmf) 时存在。

如果 $\mathcal{D}$ =1，则威舍特分布将退化为伽玛分布：

![](media/image393.wmf) （4.163）

4.5.1 逆威舍特分布

在第二章我们指出，如果！[](media/image394.wmf)，则！[](media/image395.wmf)。类似的，如果！[](media/image396.wmf)，那么！[](media/image397.wmf)，其中 IW 被称为逆威舍特（inverse Wishart），它是逆伽玛分布向多维空间的泛化。对于！[](media/image385.wmf) 和！[](media/image398.wmf)（译者注：表示 S 为正定矩阵），逆威舍特定义为：

![](media/image399.wmf) （4.164）

![](media/image400.wmf) （4.165）

逆威舍特分布具备如下的性质：

![](media/image401.wmf) （4.166）

如果 $\mathcal{D}$  = 1，该分布将退化为逆伽玛分布：

![](media/image402.wmf) （4.167）

4.5.2 威舍特分布的可视化、*

因为威舍特分布是定义在矩阵上的密度函数，所以很难绘制出它的概率密度函数。然而，我们可以很容易地从该分布上进行采样，在 2 维空间的情况

![](media/image403.png){width="5.768055555555556in" height="2.417361111111111in"}

图 4.16 威舍特分布的可视化。左图：从威舍特分布中采样得到的一些（二维）矩阵！[](media/image404.wmf)，其中 S=\[3.1653,-0.0262;-0.0262,0.6477\]，![](media/image405.wmf)。右图：边缘分布（服从 Gamma 分布）的可视化，相关系数的近似（基于采样样本的）边缘分布。如果！[](media/image405.wmf)，则关于相关系数！[](media/image406.wmf) 会有许多不确定性（图中大部分质量分布都在、[-1,1\] 之间）。采样得到的矩阵具备很高的不确定性，且有一些是奇异矩阵，当！[](media/image407.wmf) 不断增大时，采样得到的矩阵将更多地集中在先验值 S 上。（图形来自于原书）

下，我们可以使用采样得到的矩阵的特征向量去定义一个椭圆，这一点在 4.1.2 节已做解释。图 4.16 给出了一些案例。

对于高维矩阵，我们可以绘制出相应的边缘分布。威舍特分布矩阵的对角线服从伽玛分布，所以很容易就可以绘制出来。一般情况下，我们很难计算出非对角元素的分布，但是我们可以从这些分布中对矩阵进行采样，然后计算出经验分布。特别的，我们可以将每个样本矩阵转化为一个相关系数矩阵，然后利用蒙特卡洛近似法（2.7 节）去计算期望的相关系数：

![](media/image408.wmf) （4.168）

其中！[](media/image409.wmf)，![](media/image410.wmf) 表示将协方差矩阵转换为相关系数矩阵：

![](media/image411.wmf) （4.169）

为了绘制图形的目的，然后我们可以使用核密度估计（14.7.2 介绍）来产生一个单变量密度！[](media/image412.wmf) 的光滑近似，图 4.16 给出了一些例子。

4.6 MVN 的参数推理

截止目前，我们已经讨论了在高斯分布中参数！[](media/image413.wmf) 已知的情况下的推理问题。现在我们讨论如何对参数本身进行推断。我们将假设数据服从分布！[](media/image414.wmf)，其中 $i$  =1 : *N*。每个样本被全部观测到，即不存在缺失值（章节 11.6.1 将介绍如何在有缺失的情况下对参数进行估计）。为了简化我们的表达，我们分三个部分推导后验分布：首先计算！[](media/image415.wmf)；其次计算！[](media/image416.wmf)；最后计算！[](media/image417.wmf)。

4.6.1 参数！[](media/image1.wmf) 的后验分布

我们已经讨论了如何计算参数！[](media/image1.wmf) 的 MLE，现在我们讨论如何计算它的后验分布，它将有助于对参数！[](media/image1.wmf) 取值的不确定度进行建模。

似然函数的形式如下：

![](media/image418.wmf) （4.170）

为了简单起见，我们使用一个共轭先验分布，在这种情况下，即选择高斯先验分布。特别的，如果！[](media/image419.wmf)，那么我们可以基于 4.4.2.2 节得出的结论去计算！[](media/image420.wmf) 的后验分布：

![](media/image421.wmf) （4.171）

![](media/image422.wmf) （4.172）

![](media/image423.wmf) （4.173）

这与之前介绍的根据雷达的含噪"杂音"去推理目标位置的过程是一样的，只不过现在我们使用含噪的样本去推理分布的期望值（从贝叶斯角度来看，参数的不确定度与任何其他事物的不确定度没有什么区别。）

我们可以使用一个无信息先验分布，即令！[](media/image424.wmf)。在这种情况下，我们有！[](media/image425.wmf)，此时后验分布的期望等于 MLE。同时后验分布方差的下降比例为 1/*N*，这是频率统计学派的标准结果。

4.6.2 参数！[](media/image2.wmf) 的后验分布、*

我们现在讨论如何计算！[](media/image426.wmf)。似然函数具备如下形式（译者注：参考式 4.18）：

![](media/image427.wmf) （4.174）

相应的共轭先验为前文介绍的逆威舍特分布（见 4.5.1 节），其概率密度函数为：

![](media/image428.wmf) （4.175）

其中！[](media/image429.wmf) 表示自由度，![](media/image430.wmf) 为对称正定矩阵。我们发现！[](media/image431.wmf) 扮演的角色是先验散布矩阵，![](media/image432.wmf) 控制着先验分布的强度，因此与样本的数量* N *扮演同样的角色。

将似然函数与先验分布相乘，我们发现后验分布也是一个逆威舍特分布：

![](media/image433.wmf) （4.176）

![](media/image434.wmf) （4.177）

![](media/image435.wmf) （4.178）

![](media/image436.wmf) （4.179）

![](media/image437.wmf) （4.180）

总而言之，后验分布的强度！[](media/image438.wmf) 为先验分布强度！[](media/image439.wmf) 加上观测值数目* N*，后验的散布矩阵！[](media/image440.wmf) 为先验散布矩阵！[](media/image441.wmf) 加上数据的散布矩阵！[](media/image442.wmf)。

4.6.2.1 MAP 估计

从式 4.7 中我们可以发现，![](media/image443.wmf) 是一个秩为 min(*N*, $\mathcal{D}$ ) 的矩阵。如果* N*＜ $\mathcal{D}$ ，则该矩阵不是满秩矩阵，即它是不可逆的。就算* N*＞ $\mathcal{D}$ ，![](media/image443.wmf) 也是一个病态的矩阵（则几乎是奇异矩阵）。

为了解决这个问题，我们可以使用后验分布的众数（或者期望）。结果（使用与推导 MLE 的类似方法）表明 MAP 估计为：

![](media/image444.wmf) （4.181）

如果我们使用一个不合适的均匀先验分布，对应于！[](media/image445.wmf)，我们将得到 MLE。

现在让我们考虑一个合适的包含信息的先验分布，当 $\mathcal{D}$ /*N *很大（比如说大于 0.1）时，这种先验分布是很有必要的。令！[](media/image446.wmf)，所以！[](media/image447.wmf)。然后我们可以将 MAP 估计重新写成先验分布众数和 MLE 的凸组合。为了看清楚这一点，令！[](media/image448.wmf) 为先验分布的众数。然后后验分布的众数可以重写成：

![](media/image449.wmf) （4.182）

其中！[](media/image450.wmf)，它控制着向先验分布收缩的程度。

这会导致一个问题：先验分布的参数该从何处取得？通常情况下，通过交叉验证去设置！[](media/image451.wmf)。可选的方案是，我们可以使用一些文献中提供的封闭解，如果我们使用平方损失，这些解是最优的频率学派估计值。对于协方差矩阵而言，这并不是最自然的损失函数（因为它忽略了协方差矩阵是正定矩阵的约束），但它却是一个简单的估计方法。我们在后面讨论如何通过贝叶斯方法去估计！[](media/image451.wmf)。

关于先验分布的协方差矩阵！[](media/image452.wmf)，通常情况下是使用下面的先验：![](media/image453.wmf)。在这种情况下，MAP 估计为：

![](media/image454.wmf) （4.183）

所以我们发现那些对角元素与它们的 ML 估计是一致的，那些非对角元素在某种程度上向 0 收缩。这种技术所以被称作收缩估计（shrinkage estimation）或者叫正则估计（regularized estimation）。

![H:\\Work Files\\MLAPP_CODE\\MLAPP-C4-Code\\PIC\\4.17.png](media/image455.png){width="5.70400043744532in" height="2.0260870516185476in"}

图 4.17 使用* N*∈{100,50,25}个样本对一个 50 维的协方差矩阵进行估计。我们以降序的方式绘制了真实协方差矩阵的特征值（黑色实线），MLE 的特征值（蓝色点线），MAP 估计的特征值（红色实线），其中 MAP 估计使用式 4.183（![](media/image451.wmf)=0.9）。我们同时列出了在标签中每个矩阵的条件数。（图形由程序 shrinkcovDemo 生成）

MAP 估计的好处在图 4.17 中作出说明。我们考虑训练一个 50 维的高斯分布，其中三个图分别对应的样本数量为：*N*=100, *N*=50 和* N*=25。我们发现 MAP 估计往往是条件良好的，这一点与 MLE 不同。特别的，我们发现相较于 MLE，MAP 的特征值谱（eigenvalue spectrum）与真实矩阵的特征值谱更加接近。然而，特征向量不受影响。

![H:\\Work Files\\MLAPP_CODE\\MLAPP-C4-Code\\PIC\\4.18.png](media/image456.png){width="3.1843186789151354in" height="2.3680555555555554in"}

图 4.18 关于参数！[](media/image457.wmf) 的序列化更新，更新的步骤从无信息先验分布开始。数据从一个高斯分布中采样得到，该高斯分布的已知参数！[](media/image458.wmf)，未知参数！[](media/image459.wmf)。（图形由程序 gaussSeqUpdateSigma1D 生成）

当我们考虑对高维数据训练协方差矩阵时，对！[](media/image460.wmf) 估计值进行正则化的重要性将变得很明显，这一点将在后面的章节中体现。

4.6.2.2 单变量后验分布

在 1 维空间中，似然函数的形式为：

![](media/image461.wmf) （4.184）

标准的共轭先验分布为逆伽玛分布，它是逆威舍特分布的标量版本：

![](media/image462.wmf) （4.185）

将似然函数与先验分布相乘，我们发现后验分布也是一个 IG 分布：

![](media/image463.wmf) （4.186）

![](media/image464.wmf) （4.187）

![](media/image465.wmf) （4.188）

图 4.18 给出了一些说明。

后验分布的形式显然没有在多变量情况下的那么完美，因为存在一个因子 1/2。这是因为！[](media/image466.wmf)。另一个使用分布！[](media/image467.wmf) 的问题在于先验分布的强度同时由* a*~0~，*b*~0~控制。为了避免这些问题，通常情况下（在统计学的相关文献中）使用 IG 分布的一种备选的参数化，被称作逆卡方分布（inverse chi-squared distribution）。定义为：

![](media/image468.wmf) （4.189）

其中！[](media/image469.wmf) 控制着先验分布的强度，![](media/image470.wmf) 对先验分布的取值进行编码。基于这个先验分布，后验分布变成：

![](media/image471.wmf) （4.190）

![](media/image472.wmf) （4.191）

![](media/image473.wmf) （4.192）

我们发现后验分布的自由度！[](media/image474.wmf) 为先验分布自由度！[](media/image475.wmf) 加上* N*，后验分布的平方和！[](media/image476.wmf) 为先验分布的平方和！[](media/image477.wmf) 加上数据的平方和。

通过令！[](media/image478.wmf)=0，我们可以一个模拟一个无信息先验分布，![](media/image479.wmf)，这与直觉是一致的（因为它对应于 0 虚拟样本尺寸）。

4.6.3 参数！[](media/image3.wmf) 和！[](media/image2.wmf) 的后验分布、*

我们现在讨论如何计算！[](media/image480.wmf)。这些结果会有一些复杂，但是在后面的内容中会很有用。在第一次阅读时可以自由地跳过该章节。

4.6.3.1 似然函数

似然函数定义为：

![](media/image481.wmf) （4.193）

同时我们有：

![](media/image482.wmf) （4.194）

所以我们可以将似然函数重新写成：

![](media/image483.wmf) （4.195）

![](media/image484.wmf) （4.196）

我们会在下面的内容中使用这个形式。

4.6.3.2 先验分布

显然我们使用如下形式的先验分布：

![](media/image485.wmf) （4.197）

不幸的是，这并不是似然函数的共轭先验。为了说明这一点，我们发现在似然函数中参数！[](media/image3.wmf) 和！[](media/image2.wmf) 并非出现在分解的因子式中；所以它们也会联合出现在后验分布中。

上述的先验分布有时也被称为半共轭（semi-conjugate）或者条件共轭（conditionally conjugate），因为两个条件分布！[](media/image486.wmf) 和！[](media/image487.wmf) 是单独共轭的。为了创建一个全共轭先验，我们需要使用一个参数！[](media/image3.wmf) 和！[](media/image2.wmf) 彼此相关的先验分布。我们将使用一个具备如下形式的联合分布作为先验分布：

![](media/image488.wmf) （4.198）

考察式 4.196 的似然函数的形式，我们发现一个自然的共轭先验具备正态逆威舍特（Normal-inverse-wishart）或者 NIW 分布的形式，定义为：

![](media/image489.wmf) （4.199）

![](media/image490.wmf) （4.200）

![](media/image491.wmf) （4.201）

![](media/image492.wmf) （4.202）

![](media/image493.wmf) （4.203）

![](media/image494.wmf) （4.204）

![](media/image495.wmf) （4.205）

其中！[](media/image496.wmf) 为多变量伽玛函数。

NIW 的参数可以作出如下解释：![](media/image497.wmf) 为参数！[](media/image498.wmf) 的先验期望，![](media/image499.wmf) 反映了我们相信这个先验的强度；![](media/image500.wmf) 为（或正比于）参数！[](media/image501.wmf) 的先验期望，![](media/image502.wmf) 反映了我们相信这个先验的强度。

非信息（并不合适）先验分布具备如下的形式：

![](media/image503.wmf) （4.206）

![](media/image504.wmf) （4.207）

实际上，通常情况下使用一个比较弱的含信息数据依赖先验分布是比较好的。一种常见的选择是使用！[](media/image505.wmf) 和！[](media/image506.wmf)，这种设置可以确保！[](media/image507.wmf)，同时设置！[](media/image508.wmf)，并将！[](media/image509.wmf) 设置为一些比较小的数字，比如说 0.01。

4.6.3.3 后验分布

后验分布是一个参数更新后的 NIW 分布：

![](media/image510.wmf) （4.208）

![](media/image511.wmf) （4.209）

![](media/image512.wmf) （4.210）

![](media/image513.wmf) （4.211）

![](media/image514.wmf) （4.212）

![](media/image515.wmf) （4.213）

其中我们已经定义！[](media/image516.wmf) 为未中心化的平方和矩阵（这比中心化版本更容易实现逐步更新）。

这个结果事实上更符合直觉：后验分布的期望是先验分布期望和 MLE 的凸组合，其强度为！[](media/image517.wmf)；后验散布矩阵！[](media/image518.wmf) 等于先验散布矩阵！[](media/image519.wmf) 加上经验散布矩阵！[](media/image520.wmf)，再加上一个因为期望不确定度而导致的额外项（它创建了自己的虚拟散布矩阵）。

4.6.3.4 后验众数

联合分布的众数具备如下的形式：

![](media/image521.wmf) （4.214）

如果我们令！[](media/image522.wmf)，上式将退化为：

![](media/image523.wmf) （4.215）

上式相应的估计值！[](media/image524.wmf) 与式 4.182 几乎一样，但不同之处在于，1 出现在分母上，因为这是联合分布的众数，而非边缘分布的众数。

4.6.3.5 后验边缘分布

参数！[](media/image525.wmf) 的后验边缘分布为：

![](media/image526.wmf) （4.216）

边缘分布的众数和期望由下式给定：

![](media/image527.wmf) （4.217）

关于参数！[](media/image528.wmf) 的后验边缘分布服从多变量学生 T 分布：

![](media/image529.wmf) （4.218）

上述遵循一个事实：学生 T 分布可以由一个尺度化的混合高斯分布表示（见式 11.61）。

4.6.3.6 后验预测分布

后验预测分布由下式给定：

![](media/image530.wmf) （4.219）

所以它可以很容易地表达为边缘似然函数的比例。

结果表明，这个比例具备一个多变量学生-T 分布的形式：

![](media/image531.wmf) （4.220）

![](media/image532.wmf) （4.221）

学生 T 分布比高斯分布拥有一个更宽的尾域，这考虑到了！[](media/image533.wmf) 未知的事实。然而，这将会迅速地变成一个类高斯分布。

![](media/image534.png){width="5.768055555555556in" height="2.11875in"}

图 4.19 正态逆卡方分布！[](media/image535.wmf)。![](media/image536.wmf) 为先验分布的期望，![](media/image537.wmf) 表征对该期望的信念度；![](media/image538.wmf) 表示先验的方差，![](media/image539.wmf) 表征对该方差的信念度。（a）![](media/image540.wmf)。注意轮廓线（底部投影）形似一个"压缩的鸡蛋"。（b）我们增加了关于期望的信念强度，图形变得更加窄：![](media/image541.wmf)。（c）我们增加了关于方差的信念强度，图形变得更加窄：![](media/image542.wmf)。（图形由程序 NIXdemo2 生成）

4.6.3.7 标量数据的后验分布

我们现在讨论当 x 是一个 1 维变量（标量）时的情况。这些结果在统计学文献中广泛使用。与章节 4.6.2.2 一样，按照惯例，我们不使用正态逆威舍特分布，而是使用正态逆卡方（normal inverse chi-squared）分布或者 NIX 分布，定义为：

![](media/image543.wmf) （4.222）

![](media/image544.wmf) （4.223）

图 4.19 绘制了一些图形。沿着坐标轴！[](media/image545.wmf)，分布的形状类似于一个高斯分布，沿着坐标轴！[](media/image546.wmf)，分布的形状类似于！[](media/image547.wmf)；联合分布的密度是一个"压扁的鸡蛋"的形状。有趣的是，我们发现当！[](media/image548.wmf) 比较小时，![](media/image545.wmf) 的轮廓线峰值更窄，这与我们的直觉是一致的，因为如果数据的方差较小，我们就可以更加可靠地估计它的期望。

其后验分布由下式给定：

![](media/image549.wmf) （4.224）

![](media/image550.wmf) （4.225）

![](media/image551.wmf) （4.226）

![](media/image552.wmf) （4.227）

![](media/image553.wmf) （4.228）

![](media/image554.wmf) 的后验边缘分布为：

![](media/image555.wmf) （4.229）

对应的后验期望为！[](media/image556.wmf)。

关于参数！[](media/image557.wmf) 的后验边缘分布服从一个学生分布，它遵循一个事实：学生分布是高斯分布的（不同尺度下的）混合：

![](media/image558.wmf) （4.230）

其后验分布的期望为！[](media/image559.wmf)。

如果我们使用下面的非信息先验分布，那么结果看起来又是如何的呢：

![](media/image560.wmf) （4.231）

使用这个先验分布，其后验分布具备如下的形式

![](media/image561.wmf) （4.232）

其中：

![](media/image562.wmf) （4.233）

为采样标准方差（sample standard deviation）。（在章节 6.4.2，我们将显示这是一个方差的无偏估计。）因此期望的边缘后验分布由下式给定：

![](media/image563.wmf) （4.234）

参数！[](media/image564.wmf) 的后验分布方差为：

![](media/image565.wmf) （4.235）

上式的均方根被称为期望的标准差（standard error of the mean）：

![](media/image566.wmf) （4.236）

所以期望的 95%后验可靠区间（credible interval）为：

![](media/image567.wmf) （4.237）

（贝叶斯可靠区间将在章节 5.2.2 进行细节讨论；我们会在章节 6.6.1 将其与频率学派的置信区间进行对比。）

4.6.3.8 贝叶斯 t 检测

在给定数据！[](media/image568.wmf) 的情况下，假设我们希望检测一个假设！[](media/image569.wmf) （![](media/image570.wmf)），其中！[](media/image571.wmf) 是某个已知值（通常是 0）。这被称为双边，单采样 t-检测。一种简单的方式是执行这个检测从而判断是否满足！[](media/image572.wmf)。如果不满足，那么我们可以 95%的相信！[](media/image570.wmf)。一个常见的情景是我们希望测试两个样本是否有同样的期望。更加精确的表达，假设！[](media/image573.wmf) 和！[](media/image574.wmf)。我们希望通过使用数据！[](media/image575.wmf) 判断！[](media/image576.wmf) 是否成立。我们可以使用下式对这个量进行估计：

![](media/image577.wmf) （4.238）

这被称为单边，成对 t-检测（paired t-test）。（章节 5.2.3 将介绍在二项式分布数据中，成对 t-检测与非成对检测的区别。）

为了计算后验分布，我们必须指定一个先验分布。假设我们使用一个非信息先验分布。正如我们在前面介绍的，我们发现参数！[](media/image578.wmf) 的后验边缘分布具备如下形式：

![](media/image579.wmf) （4.239）

现在我们定义 t 统计量（t statistic）：

![](media/image580.wmf) （4.240）

上式的分母为期望的标准差。我们发现：

![](media/image581.wmf) （4.241）

其中！[](media/image582.wmf) 为标准学生 t 分布！[](media/image583.wmf) 的概率密度函数。

4.6.3.9 与频率学派统计的关联、*

如果我们使用一个非信息先验，结果将表明上述的贝叶斯分析方法与使用频率学派的方法一致。（我们将在第 6 章讨论频率学派统计的相关知识。）特别的，从上述结果，我们可以发现：

![](media/image584.wmf) （4.242）

这与 MLE 的采样分布具有相同的形式：

![](media/image585.wmf) （4.243）

原因在于学生分布的前两个参数是对称的，所以！[](media/image586.wmf)；因此关于参数！[](media/image587.wmf) 的后验分布的表述与！[](media/image588.wmf) 采样分布的表述具备一样的形式。因此，由频率学派测试返回的（单边）p 值（在 6.6.2 节定义）与由贝叶斯方法返回的！[](media/image589.wmf) 是一样的。程序 bayesTtestDemo 给出了一个案例。

尽管这两种方法表面上具有相似性，这两个结果还是有一个不一样的解释：在贝叶斯方法中，![](media/image587.wmf) 是未知的，![](media/image588.wmf) 是固定的，然而在频率学派的方法中，![](media/image590.wmf) 是未知的，而！[](media/image587.wmf) 是固定的。章节 7.6.3.3 将介绍更多的细节。

4.6.4 未知精度下的传感器融合、*

本节，我们将使用 4.6.3 节得到的结果，来解决如下的问题：在每一个测量设备精度未知的情况下如何实现传感器融合。这个结果是 4.4.2.2 节结果的泛化版本，在之前的结果中，测量值被建模为服从精度已知的高斯分布。当精度未知时，将得到本质上不同的结果，正如我们即将看到的，我们将得到一个多模型后验分布。

假设我们想利用由多个信源发出的数据来估计某个量！[](media/image591.wmf)，但每一个信源的可靠度未知。特别地，假设我们有两个不同的测试设备 $x$ 和 $y$ ，这两个设备具备不一样的精度：![](media/image592.wmf) 和！[](media/image593.wmf)。基于每个设备，我们得到两个独立的测试值：

![](media/image594.wmf) （4.244）

我们将针对！[](media/image595.wmf) 使用一个非信息先验分布：![](media/image596.wmf)，我们可以使用一个无穷宽的高斯分布进行模拟！[](media/image597.wmf)。如果！[](media/image598.wmf) 和！[](media/image599.wmf) 项是已知的，那么后验分布将会是一个高斯分布：

![](media/image600.wmf) （4.245）

![](media/image601.wmf) （4.246）

![](media/image602.wmf) （4.247）

其中！[](media/image603.wmf) 为设备 $x$ 的测量值数目，![](media/image604.wmf) 为设备 $y$ 的测量值数目。![](media/image605.wmf) 和！[](media/image606.wmf)。这个结果之所以成立，是因为后验分布的精度为测量设备精度的和，后验分布的期望是先验期望（等于 0）与数据期望的加权和。

然而，测量精度我们是不知道的。直觉上我们可以通过最大似然去估计它们。对数似然函数由下式给定：

![](media/image607.wmf) （4.248）

通过求解下面的联立方程，得到 MLE：

![](media/image608.wmf) （4.249）

![](media/image609.wmf) （4.250）

![](media/image610.wmf) （4.251）

我们得到：

![](media/image611.wmf) （4.252）

![](media/image612.wmf) （4.253）

![](media/image613.wmf) （4.254）

我们发现参数！[](media/image614.wmf) 的 MLE 与后验期望！[](media/image615.wmf) 的形式一样。

我们可以通过固定点迭代的方式去解这些方程。我们首先估计！[](media/image616.wmf) 和！[](media/image617.wmf) 实现参数初始化，其中！[](media/image618.wmf)，![](media/image619.wmf)。使用这些，我们得到！[](media/image620.wmf)，所以！[](media/image621.wmf)。如果我们现在迭代，我们将收敛于！[](media/image622.wmf)。

![H:\\Work Files\\MLAPP_CODE\\MLAPP-C4-Code\\PIC\\4.20.png](media/image623.png){width="4.125in" height="2.1261023622047244in"}

（a） （b）

图 4.20 参数！[](media/image624.wmf) 的后验分布。（a）点估计。（b）精确的后验分布。 （图形由程序 sensorFusionUnknownPrec 生成）

后验分布的点估计在图 4.20（a）中展示。这个点估计根据估计得到的精度值对每个传感器实现加权。因为根据估计，传感器 $y$ 的可靠度较传感器 $x$ 低，所以我们有！[](media/image625.wmf)，我们可以有效地忽略传感器 $y$ 。

我们现在使用贝叶斯方法，对未知的参数精度进行积分，而不是尝试估计它们的值。意味着，我们需要计算：

![](media/image626.wmf) （4.255）

我们使用非信息杰弗里先验分布！[](media/image627.wmf) 和！[](media/image628.wmf)。因为 $x$ 和 $y$ 项是对称的，我们可以仅仅针对其中一个。主要的积分项为：

![](media/image629.wmf) （4.256）

![](media/image630.wmf) （4.257）

考虑当前场景！[](media/image603.wmf)，上式简化为：

![](media/image631.wmf) （4.258）

我们发现上式与非归一化 Gamma 概率密度函数的积分成比例

![](media/image632.wmf) （4.259）

其中* a* = 1 和！[](media/image633.wmf)。因此积分项与伽玛分布的归一化常数！[](media/image634.wmf) 成比例，所以我们得到：

![](media/image635.wmf) （4.260）

后验分布将变成：

![](media/image636.wmf) （4.261）

精确的后验分布在图 4.20（b）中展示。我们发现它有两个峰值，一个接近！[](media/image637.wmf)，一个接近！[](media/image638.wmf)。这与如下的事实相对应：我们相信传感器 $x$ 比 $y$ 更加可靠。反之亦然。第一个众数的权重更大，因为从传感器 $x$ 中获取的数据更加一致，所以传感器 $x$ 看上去好像更加可靠。（两个传感器的可靠度显然不是一样的，因为它们所输出的数据并不一致。）然而，贝叶斯方法保留了传感器 $y$ 更加可靠的这一可能性；从两次测量中，我们无法分辨并且正好选择传感器 $x$ ，就像点估计所做的那样，导致过度置信（一个太窄的后验分布）。
